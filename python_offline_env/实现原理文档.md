# build_env.py 实现原理文档

## 📋 目录

1. [架构设计](#架构设计)
2. [核心模块](#核心模块)
3. [依赖合并算法](#依赖合并算法)
4. [环境构建流程](#环境构建流程)
5. [打包机制](#打包机制)
6. [技术选型](#技术选型)
7. [设计决策](#设计决策)

---

## 架构设计

### 整体架构

```
┌─────────────────────────────────────────────────┐
│            build_env.py 主程序                    │
├─────────────────────────────────────────────────┤
│  1. 参数解析 (parse_args)                       │
│  2. 平台检测 (detect_platform)                   │
│  3. 工具检查 (check_command_exists)             │
│  4. 依赖合并 (merge_pyproject_files)             │
│  5. 环境管理 (ensure_env_absent)                 │
│  6. Conda 环境创建                                │
│  7. 依赖安装 (uv pip install)                    │
│  8. 环境修复 (conda install --force-reinstall)    │
│  9. 环境打包 (conda-pack)                        │
│ 10. 脚本生成 (generate_install_script)          │
└─────────────────────────────────────────────────┘
```

### 数据流

```
pyproject.toml 文件
    ↓
[解析] → 提取 Python 版本、依赖列表
    ↓
[合并] → 解决版本冲突、生成统一依赖
    ↓
[创建] → Conda 环境（指定 Python 版本）
    ↓
[安装] → uv pip install（快速安装依赖）
    ↓
[修复] → conda install（修复被覆盖的文件）
    ↓
[打包] → conda-pack（生成 tar.gz）
    ↓
[生成] → 安装脚本、清单文件
```

---

## 核心模块

### 1. 依赖解析模块

**函数：** `parse_pyproject_toml(file_path: Path) -> dict`

**功能：** 解析 TOML 文件，提取项目信息

**实现：**
```python
def parse_pyproject_toml(file_path: Path) -> dict[str, Any]:
    with open(file_path, "rb") as f:
        data = tomllib.load(f)  # Python 3.11+ 标准库
    
    project = data.get("project", {})
    return {
        "requires_python": project.get("requires-python", ""),
        "dependencies": project.get("dependencies", []),
        "optional_dependencies": project.get("optional-dependencies", {}),
    }
```

**技术细节：**
- 使用 `tomllib`（Python 3.11+）或 `tomli`（兼容旧版本）
- 支持 PEP 621 标准的 `pyproject.toml` 格式
- 提取 `requires-python` 和 `dependencies` 字段

### 2. 版本解析模块

**函数：** `parse_version_spec(spec: str) -> tuple[str, str | None]`

**功能：** 解析版本规范字符串

**示例：**
```python
"pandas>=2.3.1" → ("pandas", ">=2.3.1")
"fastapi==0.127.0" → ("fastapi", "==0.127.0")
"requests" → ("requests", None)
```

**实现原理：**
- 使用正则表达式匹配包名和版本要求
- 支持 PEP 440 版本规范
- 处理可选依赖（如 `mcp[cli]`）

### 3. 版本比较模块

**函数：** `compare_versions(v1: str | None, v2: str | None) -> int`

**功能：** 比较两个版本要求，选择更严格的版本

**算法：**
1. 提取版本号部分（移除操作符）
2. 按点分割版本号
3. 逐级比较数字部分
4. 返回比较结果（-1, 0, 1）

**示例：**
```python
compare_versions(">=0.127.0", "==0.127.0") → 1  # == 更严格
compare_versions(">=3.12", ">=3.13") → -1       # 3.13 更高
```

### 4. 依赖合并模块

**函数：** `merge_pyproject_files(files: list[Path]) -> dict`

**功能：** 合并多个 `pyproject.toml` 文件的依赖

**算法流程：**

```
1. 解析所有文件
   ↓
2. 合并 Python 版本要求（选择更高版本）
   ↓
3. 合并依赖列表
   ↓
4. 对于每个包：
   a. 如果只有一个版本要求 → 直接使用
   b. 如果有多个版本要求 → 调用 compare_versions
   c. 选择更严格的版本（== > >= > >）
   ↓
5. 生成合并后的配置
```

**冲突解决策略：**

| 情况 | 策略 | 示例 |
|------|------|------|
| `>=x` vs `==x` | 选择 `==x` | `>=0.127.0` + `==0.127.0` → `==0.127.0` |
| `>=x` vs `>=y` (y > x) | 选择 `>=y` | `>=3.12` + `>=3.13` → `>=3.13` |
| `==x` vs `==y` (x ≠ y) | 警告并选择更高版本 | `==0.127.0` + `==0.128.0` → `==0.128.0` (警告) |

**实现代码：**
```python
def merge_pyproject_files(files: list[Path]) -> dict:
    all_configs = [parse_pyproject_toml(f) for f in files]
    
    # 合并 Python 版本
    python_versions = [c["requires_python"] for c in all_configs]
    merged_python = max(python_versions, key=parse_python_version)
    
    # 合并依赖
    all_deps = {}
    for config in all_configs:
        for dep in config["dependencies"]:
            name, version = parse_version_spec(dep)
            if name in all_deps:
                # 解决冲突
                existing_version = all_deps[name]
                if compare_versions(version, existing_version) > 0:
                    all_deps[name] = version
            else:
                all_deps[name] = version
    
    return {
        "requires_python": merged_python,
        "dependencies": [f"{name}{version or ''}" for name, version in all_deps.items()],
    }
```

---

## 环境构建流程

### 阶段 1：环境准备

**步骤：**
1. 检查 Conda 是否安装
2. 检查 uv 是否安装
3. 检测运行平台（Windows/WSL/Linux/macOS）
4. 创建输出目录

**平台检测实现：**
```python
def detect_platform() -> str:
    system = platform.system().lower()
    if "linux" in system:
        # 检查是否在 WSL 中
        with open("/proc/version", "r") as f:
            if "microsoft" in f.read().lower() or "wsl" in f.read().lower():
                return "wsl"
        return "linux"
    elif "windows" in system:
        return "windows"
    elif "darwin" in system:
        return "macos"
    return "unknown"
```

### 阶段 2：Conda 环境创建

**命令：**
```bash
conda create -y -p <env_path> python=<version>
```

**参数说明：**
- `-y`: 自动确认
- `-p <env_path>`: 指定环境路径（不使用名称）
- `python=<version>`: 指定 Python 版本

**为什么使用路径而不是名称？**
- 更灵活：可以指定任意路径
- 更可控：避免与现有环境冲突
- 更便携：路径可以跨机器使用

### 阶段 3：依赖安装

**使用 uv 的原因：**
1. **速度**：比 pip 快 10-100 倍
2. **可靠性**：更好的依赖解析
3. **兼容性**：完全兼容 pip 的接口

**安装命令：**
```bash
conda run -p <env_path> uv pip install --system -r requirements.txt
```

**参数说明：**
- `conda run`: 在指定环境中运行命令
- `--system`: 安装到系统 Python（即 Conda 环境）
- `-r requirements.txt`: 从文件安装依赖

**为什么使用 `conda run`？**
- 确保在正确的环境中执行
- 自动设置环境变量
- 避免路径问题

### 阶段 4：环境修复

**问题根源：**

当使用 `pip` 安装包时，可能会：
1. 覆盖 conda 管理的文件（如 `setuptools` 的 `__pycache__`）
2. 删除 conda 安装的文件
3. 导致 conda 环境元数据不一致

**conda-pack 的检查机制：**

`conda-pack` 会检查：
1. 所有 conda 安装的包的文件是否完整
2. 文件是否被修改或删除
3. 如果发现不一致，会报错

**修复策略：**

```python
# 重新安装被覆盖的包
fix_packages = ["python", "setuptools", "wheel"]
if platform in ["wsl", "linux"]:
    fix_packages.append("ncurses")

for pkg in fix_packages:
    conda install -p <env_path> --force-reinstall -y <pkg>
```

**为什么只修复这几个包？**
- `python`: 核心解释器，必须完整
- `setuptools`: 被 pip 经常覆盖
- `wheel`: 构建工具，pip 会替换
- `ncurses`: Linux 终端库，conda 管理

---

## 打包机制

### conda-pack 工作原理

**conda-pack** 是一个将 Conda 环境打包成可移植归档文件的工具。

**工作流程：**

```
1. 扫描环境目录
   ↓
2. 识别所有文件
   ↓
3. 检查文件完整性（conda 管理的文件）
   ↓
4. 生成 conda-unpack 脚本（用于修正路径）
   ↓
5. 打包成 tar.gz 或 zip
```

### --arcroot 参数

**作用：** 指定归档文件中的根目录名称

**示例：**
```bash
# 不使用 --arcroot
tar -xzf env.tar.gz
# 结果：文件直接解压到当前目录

# 使用 --arcroot env_name
conda-pack --arcroot env_name ...
tar -xzf env.tar.gz
# 结果：文件解压到 env_name/ 目录
```

**实现原理：**
- `conda-pack` 在打包时，将所有文件路径前加上 `arcroot` 前缀
- 解压时，文件会自动解压到 `arcroot` 目录

### 路径修正机制

**问题：** Conda 环境包含硬编码的路径

**示例：**
```bash
# 环境中的脚本可能包含：
#!/home/user/miniconda3/envs/my_env/bin/python
```

**解决方案：** `conda-unpack` 脚本

**工作原理：**
1. 解压后，运行 `conda-unpack`
2. 扫描所有文件，查找硬编码路径
3. 替换为新环境的路径
4. 更新 shebang 行和配置文件

**生成位置：** `bin/conda-unpack`（在打包的环境中）

---

## 技术选型

### 1. 为什么使用 Conda？

**优势：**
- ✅ 完整的 Python 环境（包含解释器）
- ✅ 不依赖系统 Python
- ✅ 支持任意 Python 版本
- ✅ 包含系统库（如 OpenSSL、zlib）
- ✅ 跨平台支持

**对比：**
| 方案 | 优点 | 缺点 |
|------|------|------|
| Conda | 完整、独立 | 体积较大 |
| venv | 轻量 | 依赖系统 Python |
| Docker | 完全隔离 | 需要 Docker 运行时 |

### 2. 为什么使用 uv？

**优势：**
- ✅ 速度极快（Rust 实现）
- ✅ 更好的依赖解析
- ✅ 兼容 pip 接口
- ✅ 支持锁定文件

**性能对比：**
- `pip install`: ~30-60 秒（32 个包）
- `uv pip install`: ~3-5 秒（32 个包）

### 3. 为什么使用 conda-pack？

**优势：**
- ✅ 专门为 Conda 环境设计
- ✅ 自动生成路径修正脚本
- ✅ 支持多种归档格式
- ✅ 检查环境完整性

**对比：**
| 方案 | 优点 | 缺点 |
|------|------|------|
| conda-pack | 专业、完整 | 需要额外安装 |
| tar | 简单 | 需要手动处理路径 |
| zip | 跨平台 | 不支持符号链接 |

---

## 设计决策

### 1. 多文件合并策略

**决策：** 选择更严格的版本

**理由：**
- 确保所有项目都能正常运行
- 避免版本冲突导致的运行时错误
- 符合"最严格约束"原则

**示例：**
```
项目 A: fastapi>=0.127.0
项目 B: fastapi==0.127.0
合并后: fastapi==0.127.0  ✅ 两个项目都能运行

如果选择 >=0.127.0:
- 可能安装 0.128.0
- 项目 B 可能不兼容  ❌
```

### 2. 环境修复策略

**决策：** 在打包前修复，而不是忽略错误

**理由：**
- 确保环境完整性
- 避免运行时问题
- 提高可移植性

**实现：**
1. 先尝试修复（重新安装被覆盖的包）
2. 如果修复失败，使用 `--ignore-missing-files`
3. 记录警告信息

### 3. 目录层级设计

**决策：** 使用 `--arcroot` 确保一级目录

**理由：**
- 避免解压时文件散落
- 更清晰的文件组织
- 符合用户期望

**实现：**
```python
pack_attempts = [
    # 优先尝试使用 --arcroot
    [conda_pack, "--arcroot", env_name, ...],
    # 如果失败，手动添加目录层级
    # ...
]
```

### 4. 平台检测与警告

**决策：** 在 Windows 上构建时给出警告

**理由：**
- Windows 环境包含 .dll 文件，不适合 Linux 服务器
- 提醒用户在正确的平台构建

**实现：**
```python
if platform == "windows":
    print("[WARN] 在 Windows 上构建的环境包含 Windows 特定文件")
    print("[WARN] 如果目标环境是 Linux，建议在 WSL 或 Linux 系统中构建")
    response = input("是否继续？(y/N): ")
```

---

## 性能优化

### 1. 并行下载

**uv 自动并行下载依赖包**

**效果：** 比 pip 快 10-100 倍

### 2. 缓存利用

**Conda 和 uv 都会缓存下载的包**

**效果：** 重复构建时更快

### 3. 增量构建

**使用 `--force` 可以删除旧环境，避免增量问题**

**建议：** 每次构建都使用 `--force` 确保干净的环境

---

## 错误处理

### 1. 优雅降级

**策略：** 尝试多种方法，如果一种失败，尝试下一种

**示例：**
```python
pack_attempts = [
    # 方式1：使用所有选项
    [conda_pack, "--arcroot", "--ignore-missing-files", ...],
    # 方式2：减少选项
    [conda_pack, "--arcroot", ...],
    # 方式3：手动添加目录层级
    # ...
]
```

### 2. 详细错误信息

**策略：** 输出详细的错误信息和解决建议

**示例：**
```python
except subprocess.CalledProcessError as e:
    print(f"[ERROR] 错误信息: {e.stderr.decode('utf-8')}")
    print(f"[INFO] 建议：检查环境状态或使用 --ignore-missing-files")
```

### 3. 清理机制

**策略：** 失败时尽量清理，成功时保留中间文件

**实现：**
- 使用 `--force` 时删除旧环境
- 构建失败时保留环境用于调试
- 成功时保留所有生成的文件

---

## 扩展性设计

### 1. 插件化架构

**当前设计支持：**
- 自定义 Conda 路径
- 自定义 uv 路径
- 自定义输出路径

**未来可扩展：**
- 自定义打包工具
- 自定义安装脚本模板
- 自定义依赖解析器

### 2. 配置驱动

**当前：** 命令行参数

**未来可扩展：** 配置文件（如 `build_config.yaml`）

### 3. 多格式支持

**当前：** tar.gz

**未来可扩展：** zip, tar.bz2, 等

---

## 安全考虑

### 1. 输入验证

- 验证文件路径存在
- 验证 Python 版本格式
- 验证依赖格式

### 2. 权限控制

- 检查文件读写权限
- 使用安全的临时目录
- 避免覆盖系统文件

### 3. 依赖安全

- 使用锁定文件确保可重现
- 记录所有依赖版本
- 支持依赖审计

---

## 总结

`build_env.py` 的设计遵循以下原则：

1. **简单易用**：命令行接口，清晰的错误信息
2. **健壮性**：多种降级策略，详细的错误处理
3. **可扩展性**：模块化设计，易于扩展
4. **性能优化**：使用快速工具（uv），并行处理
5. **可移植性**：生成可移植的环境包

通过这些设计，脚本能够可靠地构建离线 Python 环境，满足生产环境的需求。

